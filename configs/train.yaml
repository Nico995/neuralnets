# ============================================================================ #
# ================================ CONFIG FILE =============================== #
# ============================================================================ #


# --------------------------------------------------------------------- #
# -------------------------------- DATA ------------------------------- #
# --------------------------------------------------------------------- #

# ___ dataset ___ #
in_channels: &in_channels 1
in_size: &in_size 128
images: &images_dir /home/nicola/data/electron/images/training.tif
labels: &labels_dir /home/nicola/data/electron/labels_01/training.tif

dataset_base: &dataset_properties
  data: *images_dir
  labels: *labels_dir
  input_shape: &input_shape
    - *in_channels
    - *in_size
    - *in_size
  in_channels: *in_channels
  type: tif3d
  range_dir: z
  norm_type: unit

dataset: &dataset
  train:
    name: LabeledSlidingWindowDataset
    <<: *dataset_properties
    batch_size: 128
    range_split:
      - 0
      - 0.1
  val:
    name: LabeledSlidingWindowDataset
    <<: *dataset_properties
    batch_size: 128
    range_split:
      - 0.1
      - 0.8
  test:
    name: LabeledSlidingWindowDataset
    <<: *dataset_properties
    batch_size: 128
    range_split:
      - 0.8
      - 1

# ___ datamodule ___ #
datamodule:
  dataset_hparams: *dataset
  workers:
    train: 12
    val: 12
    test: 12

# ___ transforms ___ #
transforms:
  - name: rotate90
  - name: Flip
    prob: 0.5
    dim: 0


# --------------------------------------------------------------------- #
# --------------------------- OPTIMIZATION ---------------------------- #
# --------------------------------------------------------------------- #

# ___ optimizer ___ #
optimizer: &optimizer
  name: Adam
  lr: 0.0001
  weight_decay: 0.0001

# ___ scheduler ___ #
scheduler: &scheduler
  name: ReduceLROnPlateau
  monitor: val/miou
  patience: 10
  factor: 0.1
  mode: max

# ___ loss ___ #
loss: &loss
  name: CELoss

# ___ metric ___ #
metric: &metric
  name: mIoU


# --------------------------------------------------------------------- #
# -------------------------- LIGHTNING MODEL -------------------------- #
# --------------------------------------------------------------------- #

common: &common
  feature_maps: 16
  levels: 4

encoder: &encoder
  in_channels: *in_channels
  <<: *common
  norm: batch
  dropout: 0.0
  activation: relu

decoder: &decoder
  out_channels: 2
  <<: *common
  norm: batch
  dropout: 0.0
  activation: relu
  skip_connections: False

model:
  name: UNet2D
  encoder_hparams: *encoder
  decoder_hparams: *decoder
  loss_hparams: *loss
  optimizer_hparams: *optimizer
  metric_hparams: *metric
  scheduler_hparams: *scheduler
  input_shape: *input_shape
  with_labels: True
  log_images_type: masked
  save_checkpoints: True
  return_features: False

# ___ load pretrained ___ #

pretrained_model: /home/nicola/Documents/remote_pycharm_projects/neuralnets/neuralnets/train/ss_ae/unet_2d_pretext_ae/lightning_logs/version_0/checkpoints/epoch=30-step=5982.ckpt
drop_parameters:
  - decoder.output.weight
  - decoder.output.bias
freeze_weights: False


# ------------------------------------------------------------- #
# ------------------------- CALLBACKS ------------------------- #
# ------------------------------------------------------------- #

# ___ checkpoint ___ #
callbacks:
  - name: ModelCheckpoint
    save_top_k: 1
    verbose: False
    monitor: val/miou
    mode: max
    every_n_epochs: 1
  - name: EarlyStopping
    monitor: val/miou
    min_delta: 0.01
    patience: 21
    mode: max


# --------------------------------------------------------------------- #
# ------------------------- RUN CONFIGURATION ------------------------- #
# --------------------------------------------------------------------- #

# ___ trainer ___ #
trainer:
  max_epochs: 100
  gpus: '4'
  accelerator: dp
  flush_logs_every_n_steps: 10
  log_every_n_steps: 1
  progress_bar_refresh_rate: 1

seed: 0